{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Supervised Methods\n",
    "# The Learning Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **a) Load the \"banana\" data set provided in the moodle course and load the data file into scikit-learn as follows:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def loadCSV(filename):\n",
    "    f = open(filename)\n",
    "    data = np.loadtxt(f, delimiter=',')\n",
    "    X = data[:, 1:]\n",
    "    y = data[:, 0]\n",
    "    return X, y\n",
    "\n",
    "X, y = loadCSV(\"banana.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output the number $N$ of data points and the dimension $d$ of the input space $X = \\mathbb{R}^d$. Which label space $Y$ does this classification problem use? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **b) Create a numpy array of predictions according to the rule\n",
    "$$ \\hat y = h(x) = \\begin{cases}\n",
    "\t\t\t\t\t+1 & \\text{if } x_1 \\leq 0 \\\\\n",
    "\t\t\t\t\t-1 & \\text{if } x_1 > 0 \\\\\n",
    "\t\t\t\t\\end{cases} $$\n",
    "Compute the error rate, implemented by *sklearn.metrics.zero_one_loss*.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **c) Split the data into 50% \"training\" and 50% \"test\" data. For each subset output the number of points and the distribution of label values as fractions of the subset size. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The Perceptron (Implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **a) Load the \"workers\" data set provided in the moodle course. It consists of two files for inputs and labels/targets, which can be loaded with the function *numpy.load*. Print number of data points and the shape of of the input vectors.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **b) The input vectors are actually RGB images with resolution $200 \\times 100$, making for a total of $200 \\cdot 100 \\cdot 3 = 60000$ numbers (features) per images. The task is to classify the images into two categories: images with and without construction workers. This information is used to improve safety when operating large construction machines. Display a few images using the following function to get an impression of the task.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "def showimage(x):\n",
    "    plt.imshow(x)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **c) Reshape the data so that all 60000 features form a \"flat\" vector. Afterwards the data should be a two-dimensional array.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **d) Implement the Perceptron algorithm, which works as follows:**\n",
    "\n",
    "infinite loop:<br/>\n",
    "&nbsp; &nbsp; find index $i \\in \\{1, \\dots, N\\}$ such that $y_i \\cdot w^T x_i \\leq 0$<br/>\n",
    "&nbsp; &nbsp; if no such index exists then stop<br/>\n",
    "&nbsp; &nbsp; update weight vector: $w \\leftarrow w + y_i \\cdot x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **e) Test the perceptron on the following toy data. It should give a solution close to some positive multiple of $w = (1, 0)$ and $w_0 = -1$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dummy = np.array([[0.99, -1], [1.01, -1], [0.99, 1], [1.01, 1]])\n",
    "y_dummy = np.array([-1,+1,-1,+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **f) Split the worker data into two equal halves. Train the on the first half of the data. Make predictions on the second half and count the number of wrongly predicted labels. Output the error rate. Comment on the quality of the classifier - do you expect it to be useful for the task at hand? **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The Perceptron (Concepts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can measure the \"quality\" of the prediction of the perceptron by $y_i \\cdot w^T x_i$: the prediction is correct if and only if this value is positive.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **a) Updating the weight vector with a labeled point $(x_i, y_i)$ improves the prediction for that point. By which amount is the value of the linear function improved?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **b) What happens to $w^T x_j$ when updating $w$ with $(x_i, y_i)$, i.e., with a different point? Does the prediction of $(x_j, y_j)$ necessarily improve?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **c) What happens if the perceptron is run on data that is not linearly separable?**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
